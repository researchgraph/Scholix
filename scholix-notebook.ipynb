{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "from requests.utils import requote_uri\n",
    "urlString= 'http://api.scholexplorer.openaire.eu/v1/listDatasources'\n",
    "r = requests.get(urlString)\n",
    "\n",
    "#Create a URL encoded list of data sources\n",
    "dataSources=[];\n",
    "for ds in r.json():\n",
    "    if len(ds.strip())>0:\n",
    "        dataSources.append(requote_uri(ds))\n",
    "        \n",
    "        \n",
    "#Print name of datasources\n",
    "count=0\n",
    "for ds in dataSources:\n",
    "    print('{}. {}'.format(count,ds))\n",
    "    count=count+1\n",
    "    \n",
    "print('We found {} data sources.'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download files for a given datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectedDataSources={5,6,7,8,9,10,11,12,13,14,15}\n",
    "\n",
    "#Create local folder for the data sources\n",
    "for i in SelectedDataSources:\n",
    "    ds=dataSources[i]\n",
    "    if not os.path.exists(ds):\n",
    "        print ('Creating new folder: {}'.format(ds))\n",
    "        os.makedirs(ds)\n",
    "    else:\n",
    "        print ('We found a local folder for: {}'.format(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download\n",
    "downloadFiles=True\n",
    "maximumPages=1000000\n",
    "\n",
    "if downloadFiles:\n",
    "    for i in SelectedDataSources:\n",
    "        ds=dataSources[i]\n",
    "        page=0\n",
    "        statusCode=200\n",
    "        while (statusCode==200 and page < maximumPages):\n",
    "            urlString= 'https://api-dliservice-prototype-dli.d4science.org/v1/linksFromDatasource?datasource={}&page={}'.format(ds,page)\n",
    "            r = requests.get(urlString)\n",
    "            fileName='{}.json'.format(1000000+page)\n",
    "            myfile = open('./{}/{}'.format(ds,fileName), 'w')\n",
    "            myfile.write(r.text)\n",
    "            statusCode= r.status_code\n",
    "            page = page + 1\n",
    "            myfile.close\n",
    "            if page%10==0:\n",
    "                print('We have downloaded {} files for {}'.format(page,ds))\n",
    "    print('Download is complete')\n",
    "else:\n",
    "    print('Download is disabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CSV from JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, csv, pprint\n",
    "\n",
    "nodes={}\n",
    "relations=[]\n",
    "schemas=[]\n",
    "\n",
    "def addToSchemas(identifiers):\n",
    "    for i in identifiers:\n",
    "        if i['schema'] not in schemas:\n",
    "            print(i['schema'])\n",
    "            schemas.append(i['schema'])\n",
    "\n",
    "for i in SelectedDataSources:\n",
    "        ds=dataSources[i]\n",
    "        path = ds\n",
    "        dirs = os.listdir(path)\n",
    "        path = '{}/*.json'.format(ds)\n",
    "        for fname in glob.glob(path):\n",
    "            #print(fname)\n",
    "            data = json.load(open(fname))\n",
    "            for l in data:\n",
    "                addToSchemas(l['source']['identifiers'])\n",
    "                addToSchemas(l['target']['identifiers'])\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, csv, pprint\n",
    "\n",
    "nodes={}\n",
    "relations=[]\n",
    "\n",
    "def addNode(node,label,fname):\n",
    "    row={'title':'','label':label,'fname':fname}\n",
    "\n",
    "    try:\n",
    "        row['title']=node['title']\n",
    "    except Exception:\n",
    "        pass\n",
    "                \n",
    "    for i in node['identifiers']:\n",
    "        if i['schema']=='dnetIdentifier':\n",
    "            row['local_id']=i['identifier']\n",
    "        else:\n",
    "            row[i['schema']]=i['identifier']    \n",
    "\n",
    "    if row['local_id'] in nodes:\n",
    "        if 'doi' in row:\n",
    "            nodes[row['local_id']]=row\n",
    "    else:\n",
    "        nodes[row['local_id']]=row     \n",
    "\n",
    "    return row['local_id']\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "for i in SelectedDataSources:\n",
    "        ds=dataSources[i]\n",
    "        path = ds\n",
    "        dirs = os.listdir(path)\n",
    "        path = '{}/*.json'.format(ds)\n",
    "        \n",
    "        for fname in glob.glob(path):\n",
    "            print(fname)\n",
    "            data = json.load(open(fname))\n",
    "            \n",
    "            for l in data:                \n",
    "                label=''\n",
    "                for p in l['linkProvider']:\n",
    "                    if label!='':\n",
    "                        label= label +';'\n",
    "                    label= label + p['name']\n",
    "\n",
    "                source_id=addNode(l['source'],label,fname)                                                                 \n",
    "                target_id=addNode(l['target'],label,fname)\n",
    "\n",
    "                relationship_type=l['relationship']['name']        \n",
    "                relation_row=[source_id,target_id,relationship_type]\n",
    "                if relation_row not in relations:   \n",
    "                    relations.append(relation_row)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create nodes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeFile=open('nodes.csv','w')\n",
    "nodeWriter = csv.writer(nodeFile, quoting=csv.QUOTE_ALL)\n",
    "nodeWriter.writerow (['key:ID','title','doi','uri','url','local','handle','pmid','icpsr','pdb','pubmedid','genbank','geo','embl','ensembl','issn','purl','isbn','orcid','json',':LABEL'])\n",
    "\n",
    "for row in nodes.values():\n",
    "    doi=row.get('doi','')\n",
    "    uri=row.get('uri','')\n",
    "    url=row.get('url','')\n",
    "    local=row.get('local','') \n",
    "    handle=row.get('handle','') \n",
    "    pmid=row.get('pmid','') \n",
    "    icpsr=row.get('icpsr','') \n",
    "    pdb=row.get('pdb','') \n",
    "    pubmedid=row.get('pubmedid','')\n",
    "    genbank=row.get('genbank','')\n",
    "    geo=row.get('geo','')\n",
    "    embl=row.get('embl','')\n",
    "    ensembl=row.get('ensembl','')\n",
    "    issn=row.get('issn','')\n",
    "    purl=row.get('purl','')\n",
    "    isbn=row.get('isbn','')\n",
    "    orcid=row.get('orcid','')\n",
    "    nodeWriter.writerow ([row['local_id'],row['title'],doi,uri,url,local,handle,pmid,icpsr,pdb,pubmedid,'genbank','geo','embl','ensembl','issn','purl','isbn','orcid,row['fname'],row['label']])\n",
    "    \n",
    "nodeFile.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create relations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeFile=open('relations.csv','w')\n",
    "nodeWriter = csv.writer(nodeFile, quoting=csv.QUOTE_ALL)\n",
    "nodeWriter.writerow ([':START_ID',':END_ID',':TYPE'])\n",
    "\n",
    "for row in relations:\n",
    "    nodeWriter.writerow(row)\n",
    "    \n",
    "nodeFile.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
